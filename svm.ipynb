{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install cvxopt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom scipy.spatial.distance import pdist, squareform\nfrom cvxopt import matrix as cvxopt_matrix\nfrom cvxopt import solvers as cvxopt_solvers\nimport os\nimport numpy as np\nimport pandas as pd \nimport os\nfrom math import sqrt,exp\nfrom numpy.linalg import inv,det\nfrom numpy import array\nfrom numpy import mean\nfrom numpy import cov\nfrom numpy.linalg import eig\nfrom numpy import asarray\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_train.csv\")\ny_train=train['label']\nX_train=train.drop(['label'],axis=1)\nX_train=np.array(X_train)\ny_train=np.array(y_train)\ny_train=np.reshape(y_train,(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=[]\ny=[]\nfor i in range(len(X_train)):\n    if y_train[i]==0 or y_train[i]==1:\n        X.append(X_train[i])\n        y.append(y_train[i])\nX=np.array(X)\ny=np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y[y==0]=-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,y,stratify=y,test_size=0.3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_mean = x_train.mean(axis=0)\nx_train = x_train - col_mean\ncol_std = x_train.std(axis=0)\nfor i in range(x_train.shape[1]):\n    if(col_std[i] != 0):\n        x_train[:,i] = x_train[:,i]/(col_std[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_mean = x_test.mean(axis=0)\nx_test = x_test - col_mean\ncol_std = x_test.std(axis=0)\nfor i in range(x_test.shape[1]):\n    if(col_std[i] != 0):\n        x_test[:,i] = x_test[:,i]/(col_std[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_acc(predictions,y_test):\n    acc=0\n    predictions=np.reshape(predictions,(-1,1))\n    y_test=np.reshape(y_test,(-1,1))\n    for i in range(len(predictions)):\n        if predictions[i]==y_test[i]:\n            acc+=1\n    return acc/y_test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_pca(X,k):\n    # calculate the mean of each column\n    M = mean(X.T, axis=1)\n    # center columns by subtracting column means\n    C = X - M\n    # calculate covariance matrix of centered matrix\n    V = cov(C.T)\n    # eigendecomposition of covariance matrix\n    values, vectors = eig(V)\n    # K is number of dimensions we want \n    max_vectors = vectors[:k]\n    # project data\n#     print(max_vectors.shape)\n#     P = max_vectors.dot(C.T)\n    return max_vectors.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs=[0.001,0.1,1,10,100,1000]\ngamma=0.01\nthreshold=1e-4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for C in cs:\n    m,n = x_train.shape\n    y = y_train.reshape(-1,1) * 1.\n    x_dash = y * x_train\n    H = np.dot(x_dash , x_dash.T) * 1.\n\n    #Converting into cvxopt format\n    P = cvxopt_matrix(H)\n#     print(P)\n    q = cvxopt_matrix(-np.ones((m, 1)))\n    G = cvxopt_matrix(np.vstack((np.diag(-np.ones(m)), np.identity(m))))\n    h = cvxopt_matrix(np.hstack((np.zeros(m), np.ones(m)*C)))\n    A = cvxopt_matrix(y.reshape(1, -1))\n    b = cvxopt_matrix(np.zeros(1))\n    #Setting solver parameters (change default to decrease tolerance) \n    cvxopt_solvers.options['show_progress'] = False\n    cvxopt_solvers.options['abstol'] = 1e-10\n    cvxopt_solvers.options['reltol'] = 1e-10\n    cvxopt_solvers.options['feastol'] = 1e-10\n    #Run solver\n    sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n    alphas = np.ravel(sol['x'])\n    alphas=np.reshape(alphas,(-1,1))\n    S=np.where(alphas > threshold)[0]\n    temp=alphas[S]*y_train[S]\n    w=np.sum(temp*x_train[S],axis=0)\n    w=np.reshape(w,(-1,1))\n    b=-0.5*(np.max(np.dot(x_train,w)[y_train==-1])+np.min(np.dot(x_train,w)[y_train==1]))\n    predict=np.sign(np.dot(x_test,w)+b)\n    predict[predict<0]=-1\n    print(\"Value of C : \"+str(C))\n    print(\"No. of support vectors : \"+str(len(S)))\n    print(\"Accuracy : \"+str(get_acc(predict,y_test)))\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"C=0.1\nfor feats in range(100,800,100):\n    vecs=do_pca(x_train,feats)\n    new_x_train=np.dot(x_train,vecs)\n    print(new_x_train.shape)\n    new_x_test=np.dot(x_test,vecs)\n    m,n = new_x_train.shape\n    y = y_train.reshape(-1,1) * 1.\n    x_dash = y * new_x_train\n    H = np.dot(x_dash , x_dash.T) * 1.\n#     print(H.shape)\n    #Converting into cvxopt format\n    P = cvxopt_matrix(H)\n#     print(P)\n    q = cvxopt_matrix(-np.ones((m, 1)))\n    G = cvxopt_matrix(np.vstack((np.diag(-np.ones(m)), np.identity(m))))\n    h = cvxopt_matrix(np.hstack((np.zeros(m), np.ones(m)*C)))\n    A = cvxopt_matrix(y.reshape(1, -1))\n    b = cvxopt_matrix(np.zeros(1))\n    #Setting solver parameters (change default to decrease tolerance) \n    cvxopt_solvers.options['show_progress'] = False\n    cvxopt_solvers.options['abstol'] = 1e-10\n    cvxopt_solvers.options['reltol'] = 1e-10\n    cvxopt_solvers.options['feastol'] = 1e-10\n    #Run solver\n    sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n    alphas = np.ravel(sol['x'])\n    alphas=np.reshape(alphas,(-1,1))\n    S=np.where(alphas > threshold)[0]\n    temp=alphas[S]*y_train[S]\n    w=np.sum(temp*new_x_train[S],axis=0)\n    w=np.reshape(w,(-1,1))\n    b=-0.5*(np.max(np.dot(new_x_train,w)[y_train==-1])+np.min(np.dot(new_x_train,w)[y_train==1]))\n    predict=np.sign(np.dot(new_x_test,w)+b)\n    predict[predict<0]=-1\n    print(\"No. of features : \"+str(feats))\n    print(\"No. of support vectors : \"+str(len(S)))\n    print(\"Accuracy : \"+str(get_acc(predict,y_test)))\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}